import os
import librosa
import numpy as np
import subprocess
import matplotlib.pyplot as plt
from tqdm import tqdm

# âœ… ì„¤ì •
input_root = 'dev/youngmin/raw_data'  # ì˜¤ë””ì˜¤ ì›ë³¸
output_root = 'dev/youngmin/outputs'  # ê²°ê³¼ ì €ì¥ í´ë”
sampling_rate = 22050
n_mfcc = 13
hop_length = 512
segment_duration_sec = 1.0  # âš ï¸ 1ì´ˆ ë‹¨ìœ„
save_visuals = True

frames_per_second = sampling_rate / hop_length
target_frame_len = int(frames_per_second * segment_duration_sec)

X_features, y_labels = [], []

label_names = ['quiet', 'neutral', 'noisy']
label_to_index = {name: idx for idx, name in enumerate(label_names)}

def convert_to_wav(input_path, output_path):
    if not os.path.exists(output_path):
        command = ['ffmpeg', '-y', '-i', input_path, '-ac', '1', '-ar', str(sampling_rate), output_path]
        subprocess.run(command, check=True)

# ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
for label in label_names:
    vis_path = os.path.join(output_root, 'visuals', label)
    os.makedirs(vis_path, exist_ok=True)

# ğŸ“¦ ì „ì²˜ë¦¬ ì‹œì‘
for label in label_names:
    folder_path = os.path.join(input_root, label)
    label_index = label_to_index[label]

    if not os.path.exists(folder_path):
        print(f"âš ï¸ ê²½ë¡œ ì—†ìŒ: {folder_path}")
        continue

    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.wav', '.mp3', '.m4a', '.mp4'))]
    print(f"ğŸ§ [{label}] ì´ {len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")

    for fname in tqdm(files, desc=f"[{label}] ì „ì²˜ë¦¬", unit="file"):
        filepath = os.path.join(folder_path, fname)

        if fname.lower().endswith(('.mp3', '.mp4', '.m4a')):
            wav_name = os.path.splitext(fname)[0] + '.wav'
            wav_path = os.path.join(folder_path, wav_name)
            convert_to_wav(filepath, wav_path)
            filepath = wav_path

        base_name = os.path.splitext(fname)[0]
        try:
            duration = librosa.get_duration(path=filepath)
        except:
            print(f"â— duration ì½ê¸° ì‹¤íŒ¨: {filepath}")
            continue

        segment_count = int(duration // segment_duration_sec)

        for i in range(segment_count):
            offset_sec = i * segment_duration_sec
            try:
                audio_data, _ = librosa.load(filepath, sr=sampling_rate, offset=offset_sec, duration=segment_duration_sec)
            except:
                print(f"â— ë¡œë“œ ì‹¤íŒ¨: {filepath} (ì„¸ê·¸ë¨¼íŠ¸ {i})")
                continue

            mfcc = librosa.feature.mfcc(y=audio_data, sr=sampling_rate, n_mfcc=n_mfcc, hop_length=hop_length)
            zcr = librosa.feature.zero_crossing_rate(y=audio_data, hop_length=hop_length)
            features = np.vstack([mfcc, zcr])

            if features.shape[1] < target_frame_len:
                features = np.pad(features, ((0, 0), (0, target_frame_len - features.shape[1])), mode='constant')
            else:
                features = features[:, :target_frame_len]

            X_features.append(features.T)
            y_labels.append(label_index)

            if save_visuals:
                vis_path = os.path.join(output_root, 'visuals', label, f"{base_name}_seg{i+1}.png")
                plt.figure(figsize=(10, 4))
                plt.imshow(features, aspect='auto', origin='lower', cmap='coolwarm')
                plt.title(f"{base_name}_seg{i+1} - {label}")
                plt.xlabel("Frame")
                plt.ylabel("Feature Index (MFCC+ZCR)")
                plt.colorbar()
                plt.tight_layout()
                plt.savefig(vis_path)
                plt.close()

# âœ… ì €ì¥
os.makedirs(output_root, exist_ok=True)
np.save(os.path.join(output_root, "X_lstm.npy"), np.array(X_features))
np.save(os.path.join(output_root, "y_lstm.npy"), np.array(y_labels))

# âœ… ì¶œë ¥
print("âœ… segment_duration (ì´ˆ):", segment_duration_sec)
print("âœ… target_frame_len:", target_frame_len)
print("âœ… X shape:", np.array(X_features).shape)
print("âœ… y shape:", np.array(y_labels).shape)
print("ğŸ“ ì €ì¥ ì™„ë£Œ:", output_root)
