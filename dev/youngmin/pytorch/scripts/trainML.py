import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from pathlib import Path
import mlflow
import mlflow.pytorch
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
import matplotlib.pyplot as plt
import os



# 1. ëª¨ë¸ ì •ì˜
class AudioCNN(nn.Module):
    def __init__(self):
        super(AudioCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(4032, 64)  # ì—¬ê¸° ìˆ˜ì •!
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(64, 1)

    def forward(self, x):
        x = torch.relu(self.pool1(self.conv1(x)))
        x = torch.relu(self.pool2(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.sigmoid(self.fc2(x))
        return x


# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
x = np.load("../data/x.npy")  # shape: (9374, 86, 14)
y = np.load("../data/y.npy")  # shape: (9374,)

# ğŸ”¸ float32 ë³€í™˜ (PyTorchëŠ” float32 ê¶Œì¥)
x = x.astype(np.float32)
y = y.astype(np.float32)

# ğŸ”¸ ì±„ë„ ì°¨ì› ì¶”ê°€ (PyTorchìš©: (N, 1, H, W))
x = np.expand_dims(x, axis=1)  # shape: (9374, 1, 86, 14)

# ğŸ”¸ í‘œì¤€ ì •ê·œí™” (z-score)
x = (x - x.mean()) / x.std()

# ğŸ”¸ í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

# ğŸ”¸ í…ì„œë¡œ ë³€í™˜
train_dataset = TensorDataset(torch.tensor(x_train), torch.tensor(y_train))
val_dataset = TensorDataset(torch.tensor(x_val), torch.tensor(y_val))

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32)


# 3. í•™ìŠµ ì¤€ë¹„
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AudioCNN().to(device)

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 4. í•™ìŠµ ë£¨í”„
best_val_loss = float('inf')
patience, wait = 5, 0

for epoch in range(30):
    model.train()
    running_loss = 0.0
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device).unsqueeze(1)
        optimizer.zero_grad()
        preds = model(xb)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device).unsqueeze(1)
            preds = model(xb)
            val_loss += criterion(preds, yb).item()

    avg_train_loss = running_loss / len(train_loader)
    avg_val_loss = val_loss / len(val_loader)

    print(f"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        wait = 0
        torch.save(model.state_dict(), "../model/cnn_model.pt")
        print(" ëª¨ë¸ ì €ì¥ë¨")
    else:
        wait += 1
        if wait >= patience:
            print(" Early Stopping")
            break
# MLflow ì„¤ì •
mlflow.set_tracking_uri("http://210.101.236.174:5000")
mlflow.set_experiment("Classroom Noise Detection")

with mlflow.start_run(run_name="Baeyoungmin"):

    mlflow.log_param("batch_size", 32)
    mlflow.log_param("epochs", 30)
    mlflow.log_param("optimizer", "Adam")
    mlflow.log_param("learning_rate", 0.001)
    mlflow.log_param("loss_function", "BCELoss")

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    mlflow.pytorch.log_model(model, "model")

    # ê²€ì¦ìš© ì˜ˆì¸¡ ë° í˜¼ë™í–‰ë ¬
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for xb, yb in val_loader:
            xb = xb.to(device)
            preds = model(xb).cpu().numpy()
            all_preds.extend((preds > 0.5).astype(int).flatten())
            all_labels.extend(yb.numpy().astype(int))

    acc = accuracy_score(all_labels, all_preds)
    mlflow.log_metric("val_accuracy", acc)

    # í˜¼ë™ í–‰ë ¬ ì €ì¥ ë° ë¡œê¹…
    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["quiet", "loud"])
    disp.plot()
    plt.title("Confusion Matrix")
    cm_path = "confusion_matrix.png"
    plt.savefig(cm_path)
    mlflow.log_artifact(cm_path)
    plt.close()

    # ì†ì‹¤ê°’ ì‹œê°í™” (í•™ìŠµ ê³¼ì •ì—ì„œ ìˆ˜ì§‘ í•„ìš”)
    train_losses = []  # ë£¨í”„ì—ì„œ ë§¤ epochë§ˆë‹¤ append í•„ìš”
    val_losses = []    # ë£¨í”„ì—ì„œ ë§¤ epochë§ˆë‹¤ append í•„ìš”

    # ... ìœ„ í•™ìŠµ ë£¨í”„ ë‚´ì—ì„œ
    # train_losses.append(avg_train_loss)
    # val_losses.append(avg_val_loss)

    # ê·¸ë˜í”„ ì €ì¥ ë° ë¡œê¹…
    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Training & Validation Loss")
    loss_path = "loss_graph.png"
    plt.savefig(loss_path)
    mlflow.log_artifact(loss_path)
    plt.close()