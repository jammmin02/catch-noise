import torch
import onnx
import json
from model import CNNLSTM

# âœ… 1. best_params.json ë¡œë“œ
with open("best_params.json", "r") as f:
    best_params = json.load(f)

# âœ… 2. ëª¨ë¸ ì •ì˜ (best trial ê¸°ì¤€)
model = CNNLSTM(
    conv1_filters=best_params["conv1_filters"],
    conv2_filters=best_params["conv2_filters"],
    lstm_units=best_params["lstm_units"],
    dense_units=best_params["dense_units"],
    dropout=best_params["dropout"]
).to("cpu")

# âœ… 3. í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
model.load_state_dict(torch.load("best_model.pt", map_location="cpu"))
model.eval()

# âœ… 4. ë”ë¯¸ ì…ë ¥ (ì…ë ¥ shapeì€ [B, C=1, H=86, W=14])
dummy_input = torch.randn(1, 1, 86, 14)
print("ğŸ§ª dummy_input shape:", dummy_input.shape)
assert dummy_input.dim() == 4, f"âŒ ì…ë ¥ í…ì„œê°€ 4ì°¨ì›ì´ ì•„ë‹™ë‹ˆë‹¤: {dummy_input.shape}"

# âœ… 5. ONNX ë³€í™˜
torch.onnx.export(
    model,
    dummy_input,
    "best_model.onnx",
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
    opset_version=11
)
print("âœ… PyTorch â†’ ONNX ë³€í™˜ ì™„ë£Œ: best_model.onnx")

# âœ… 6. ONNX ëª¨ë¸ ê²€ì¦
onnx_model = onnx.load("best_model.onnx")
onnx.checker.check_model(onnx_model)
print("âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!")
