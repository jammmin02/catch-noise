import torch
import torch.nn as nn

class CNNOnly(nn.Module):
    def __init__(self, conv1_filters, conv2_filters, dense_units, dropout):
        super().__init__()

        self.features = nn.Sequential(
            nn.Conv2d(1, conv1_filters, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(conv1_filters, conv2_filters, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        # ğŸ”½ input feature ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ê³„ì‚°
        self.flatten_dim = None  # ì²˜ìŒì— Noneìœ¼ë¡œ ë‘ê³  forwardì—ì„œ ê³„ì‚°

        self.classifier_head = nn.Sequential(
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dense_units, 1),
            nn.Sigmoid()
        )

        self.dense_units = dense_units
        self.dropout = dropout
        self.conv2_filters = conv2_filters

    def forward(self, x):
      x = self.features(x)
      B = x.size(0)
      x = x.view(B, -1)  # flatten

      if self.flatten_dim is None:
        self.flatten_dim = x.size(1)
        # Linear ê³„ì¸µ ì •ì˜ + ìë™ device ì ìš©
        self.classifier = nn.Sequential(
            nn.Linear(self.flatten_dim, self.dense_units),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(self.dense_units, 1),
            nn.Sigmoid()
        ).to(x.device)  # ğŸ”¥ ì¤‘ìš”: ì´ê±¸ë¡œ GPUì— ìë™ ì´ë™ë¨

      return self.classifier(x)