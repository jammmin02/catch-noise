import os
import librosa
import numpy as np
import subprocess
import matplotlib.pyplot as plt
import pandas as pd
from tqdm import tqdm
import random
import uuid
import librosa.display

# ì„¤ì •
base_dir = 'data'
output_dir = 'dev/jungmin/2class_noisy_vs_nonnoisy/outputs/cnn_lstm'
sr = 22050
n_mfcc = 13
hop_length = 512
segment_duration = 2.0  # ğŸ”„ ë³€ê²½ë¨
save_visuals = True

frame_per_second = sr / hop_length
max_len = int(frame_per_second * segment_duration)

# âœ… 2-class: non_noisy (0), noisy (1)
label_names = ['non_noisy', 'noisy']
label_map = {name: idx for idx, name in enumerate(label_names)}

X, y, logs = [], [], []

# ì‹œê°í™”ìš© í´ë” ìƒì„±
for label_name in label_names:
    os.makedirs(os.path.join(output_dir, 'visuals', label_name), exist_ok=True)

def convert_to_wav(src_path, dst_path):
    if not os.path.exists(dst_path):
        print(f"ğŸ”„ ë³€í™˜ ì¤‘: {src_path} â†’ {dst_path}")
        command = ['ffmpeg', '-y', '-i', src_path, '-ac', '1', '-ar', str(sr), dst_path]
        subprocess.run(command, check=True)

# ë°ì´í„° ì²˜ë¦¬
for label_name in label_names:
    folder_path = os.path.join(base_dir, label_name)
    label = label_map[label_name]

    if not os.path.exists(folder_path):
        print(f"âš ï¸ í´ë” ì—†ìŒ: {folder_path} â†’ ê±´ë„ˆëœ€")
        continue

    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.wav', '.mp4', '.m4a', '.mp3'))]
    print(f"ğŸ§ [{label_name}] ì´ {len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")

    for file_name in tqdm(files, desc=f"[{label_name}] ì „ì²˜ë¦¬", unit="file"):
        file_path = os.path.join(folder_path, file_name)
        print(f"ğŸ“‚ íŒŒì¼ ì‹œì‘: {file_path}")

        if file_name.lower().endswith(('.mp4', '.m4a', '.mp3')):
            wav_name = os.path.splitext(file_name)[0] + '.wav'
            wav_path = os.path.join(folder_path, wav_name)
            convert_to_wav(file_path, wav_path)
            file_path = wav_path
            print(f"âœ… ë³€í™˜ ì™„ë£Œ: {file_path}")

        base_filename = os.path.splitext(file_name)[0]
        try:
            total_duration = librosa.get_duration(path=file_path)
            print(f"â±ï¸ ê¸¸ì´ í™•ì¸ ì™„ë£Œ: {total_duration:.2f}s")
        except:
            print(f"â— duration ì½ê¸° ì‹¤íŒ¨: {file_path}")
            continue

        segment_count = int(total_duration // segment_duration)
        if segment_count == 0:
            print(f"â© ì§§ì€ ì˜¤ë””ì˜¤ ìŠ¤í‚µ: {file_path}")
            continue

        for i in range(segment_count):
            offset = i * segment_duration
            try:
                print(f"ğŸ§ segment {i+1}/{segment_count} ì¶”ì¶œ ì¤‘ (offset={offset:.1f}s)...")
                y_audio, _ = librosa.load(file_path, sr=sr, offset=offset, duration=segment_duration)
            except:
                print(f"â— load ì‹¤íŒ¨: {file_path} (segment {i})")
                continue

            mfcc = librosa.feature.mfcc(y=y_audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)
            zcr = librosa.feature.zero_crossing_rate(y=y_audio, hop_length=hop_length)
            zcr_mean = np.mean(zcr)
            zcr_feature = np.full((1, mfcc.shape[1]), zcr_mean)
            features = np.vstack([mfcc, zcr_feature])

            if features.shape[1] < max_len:
                features = np.pad(features, ((0, 0), (0, max_len - features.shape[1])), mode='constant')
            else:
                features = features[:, :max_len]

            X.append(features.T.astype(np.float32))
            y.append(label)

            log_entry = {
                "file": file_name,
                "segment": i + 1,
                "label": label_name,
                "uuid": str(uuid.uuid4())
            }
            logs.append(log_entry)

            if save_visuals:
                save_filename = f"{label_name}_{base_filename}_seg{i+1}_{log_entry['uuid']}.png"
                save_path = os.path.join(output_dir, 'visuals', label_name, save_filename)

                try:
                    fig, ax = plt.subplots(3, 1, figsize=(12, 10))

                    # âœ… waveform ì§ì ‘ ê·¸ë¦¬ê¸°
                    t = np.linspace(0, len(y_audio)/sr, len(y_audio))
                    ax[0].plot(t, y_audio, color='steelblue')
                    ax[0].set_title(f"Waveform - Segment {i+1}")
                    ax[0].set_xlabel("Time (s)")
                    ax[0].set_ylabel("Amplitude")

                    # âœ… MFCC
                    img = librosa.display.specshow(mfcc, x_axis="time", sr=sr, hop_length=hop_length, ax=ax[1])
                    ax[1].set_title("MFCC")
                    fig.colorbar(img, ax=ax[1], format="%+2.f dB")

                    # âœ… ZCR
                    ax[2].plot(np.linspace(0, segment_duration, zcr.shape[1]), zcr[0], color='darkgreen')
                    ax[2].set_title("Zero Crossing Rate")
                    ax[2].set_xlabel("Time (s)")
                    ax[2].set_ylabel("ZCR")

                    plt.tight_layout()
                    plt.savefig(save_path)
                    plt.close()
                    print(f"ğŸ–¼ï¸ ì‹œê°í™” ì €ì¥: {save_path}")
                except Exception as e:
                    print(f"â— ì‹œê°í™” ì˜¤ë¥˜ ë°œìƒ (ì„¸ê·¸ë¨¼íŠ¸ {i+1}): {e}")

# ğŸ¯ ì˜¤ë²„ìƒ˜í”Œë§ (í´ë˜ìŠ¤ë³„ í‰ê·  ìˆ˜ë¡œ ë§ì¶”ê¸°)
print("ğŸ“Š í´ë˜ìŠ¤ ê· í˜• ë§ì¶”ëŠ” ì¤‘...")
data_by_label = {i: [] for i in range(len(label_names))}
for feat, lab in zip(X, y):
    data_by_label[lab].append(feat)

mean_len_class = int(np.mean([len(v) for v in data_by_label.values()]))

X_balanced, y_balanced = [], []
for label, feats in data_by_label.items():
    if len(feats) == 0:
        print(f"âš ï¸ í´ë˜ìŠ¤ '{label_names[label]}'ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    if len(feats) >= mean_len_class:
        selected_feats = random.sample(feats, mean_len_class)
    else:
        repeats = mean_len_class // len(feats)
        remainder = mean_len_class % len(feats)
        selected_feats = feats * repeats + random.sample(feats, remainder)
    X_balanced.extend(selected_feats)
    y_balanced.extend([label] * mean_len_class)

# ì‹œê°í™”: ì˜¤ë²„ìƒ˜í”Œë§ ê²°ê³¼
original_counts = {label_names[k]: len(v) for k, v in data_by_label.items()}
oversampled_counts = {label_names[k]: mean_len_class for k in data_by_label.keys() if len(data_by_label[k]) > 0}

labels = list(original_counts.keys())
x = range(len(labels))
width = 0.35

fig, ax = plt.subplots()
ax.bar([i - width/2 for i in x], original_counts.values(), width, label='Original', color='skyblue')
ax.bar([i + width/2 for i in x], oversampled_counts.values(), width, label='Oversampled', color='salmon')

ax.set_ylabel('Sample Count')
ax.set_title('Sample Count by Class (Before vs After Oversampling)')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "oversampling_visualization.png"))
plt.show()

# ì €ì¥
os.makedirs(output_dir, exist_ok=True)
np.save(os.path.join(output_dir, "X_lstm.npy"), np.array(X_balanced, dtype=np.float32))
np.save(os.path.join(output_dir, "y_lstm.npy"), np.array(y_balanced, dtype=np.int32))
pd.DataFrame(logs).to_csv(os.path.join(output_dir, "segment_logs.csv"), index=False)

# ì¶œë ¥
print("âœ… segment_duration:", segment_duration)
print("âœ… max_len:", max_len)
print("âœ… X shape:", np.array(X_balanced).shape)
print("âœ… y shape:", np.array(y_balanced).shape)
print("ğŸ“ ì €ì¥ ì™„ë£Œ:", output_dir)
print("ğŸ“ ì‹œê°í™” ì €ì¥ ì™„ë£Œ:", os.path.join(output_dir, "oversampling_visualization.png"))